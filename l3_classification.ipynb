{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Классификация текстов\n",
    "\n",
    "## Екатерина Черняк\n",
    "\n",
    "echernyak@hse.ru\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Постановка задачи\n",
    "\n",
    "* $d \\in D$ – документы\n",
    "* $c \\in C$ – классы \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Бинарная классификация: $C = \\{0, 1\\}$ \n",
    "* Многоклассовая классификация [multiclass classification]: $C = \\{0, ..., K\\}$\n",
    "* Многотемная классификация [multi-label classification]: $C = \\{0,1\\}^K$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Примеры\n",
    "\n",
    "* Фильтрация спама: $C = \\{spam, ham\\}$ – бинарная классификация\n",
    "* Классификация по тональности: $C =  \\{neutral, positive, negative\\}$ – классификация с тремя классами\n",
    "* Рубрикация: $C \\in \\{религия, праздники, спорт, фестивали, ... \\}$ – классификация на несколько тем\n",
    "* Определение авторства:\n",
    "    * Этим ли автором написан текст: $ C = \\{0, 1\\}$?\n",
    "    * Кем из этих авторов написан текст: $ C = \\{a_1, a_2, a_3, ... \\}$?\n",
    "    * Пол автора: $ C = \\{f, m\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Методы классификации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### По правилам\n",
    "\n",
    "* Если в предложении встречается личное местоимение первого лица и глагол с окончанием женского рода, то пол автора = $f$.\n",
    "* Если доля положительно окрашенных прилагательтельных в отзыве больше доли отрицательно окрашенных прилагательных, то отзыв относится к классу $posititive$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### С использованием алгоритмов машинного обучения \n",
    "\n",
    "$ \\gamma : D \\rightarrow C$ - алгоритм классификации\n",
    "\n",
    "$({D^{train}, C^{train}})$ – обучающее множество \n",
    "\n",
    "$({D^{test}, C^{test}})$ – тестовое множество \n",
    "\n",
    "#### Основные методы\n",
    "* Метод наивного Байеса\n",
    "* Логистическая регрессия \n",
    "* Сверточные нейронные сети\n",
    "* FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Меры качества бинарной классификации \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
    "    <th colspan=\"2\">gold <br>standart</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>positive</td>\n",
    "    <td>negative</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">classification <br>output</td>\n",
    "    <td>positive</td>\n",
    "    <td>$tp$</td>\n",
    "    <td>$fp$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>negative</td>\n",
    "    <td>$fn$</td>\n",
    "    <td>$tn$</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$precision = Pr =  \\frac{tp}{tp+fp} $ – точность \n",
    "\n",
    "$recall = R = \\frac{tp}{tp+fn} $ – полнота \n",
    "\n",
    "$F_2 = \\frac{2 Pr * R}{Pr + R}$ – $F$-мера \n",
    "\n",
    "$accuracy = \\frac{tp + tn}{tp + fp + fn + tn}$ –  аккуратность  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Меры качества многоклассовой классификации \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th colspan=\"3\">gold <br>standart</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>$class_1$</td>\n",
    "    <td>$class_2$</td>\n",
    "    <td>$class_3$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"3\">classification <br>output</td>\n",
    "    <td>$class_1$</td>\n",
    "    <td>$tp_1$</td>\n",
    "    <td>$fp_{12}$</td>\n",
    "    <td>$fp_{13}$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$class_2$</td>\n",
    "    <td>$fn_{21}$</td>\n",
    "    <td>$tp_2$</td>\n",
    "    <td>$fp_{23}$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$class_3$</td>\n",
    "    <td>$fn_{31}$</td>\n",
    "    <td>$fn_{32}$</td>\n",
    "    <td>$tp_3$</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Микро-усреднение:\n",
    "\n",
    "$micro-precision = micro-Pr =  \\frac{\\sum tp_i}{\\sum tp_i + \\sum fp_i} $ \n",
    "\n",
    "$micro-recall = micro-R = \\frac{\\sum tp_i}{\\sum tp_i+ \\sum fn_i } $\n",
    "\n",
    "Макро-усреднение:\n",
    "\n",
    "$macro-precision = macro-Pr =  \\frac{\\sum Pr_i}{|C|} $\n",
    "\n",
    "$macro-recall = macro-R = \\frac{\\sum R_i}{|C|} $ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Источники данных\n",
    "* IMDB \n",
    "* newsgroup20\n",
    "* Reuters \n",
    "* Кинопоиск\n",
    "* Научные статьи\n",
    "* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## (Напоминание) Векторная модель: документ – вектор признаков \n",
    "\n",
    "* $d \\in D$ – документы\n",
    "* $w \\in V$ – словарь, всего слов |V|\n",
    "\n",
    "* традиционное представление: одно слово – одна размерность в векторной модели: $\\vec{d_i} = <f_1, ... , f_{|V|}> $\n",
    "* $f$ – компоненты вектора – могут быть:\n",
    "    * 0 и 1\n",
    "    * частотами\n",
    "    * $tf-idf$ весами\n",
    "* с использованием распределенных представлений слов [word embeddings]:\n",
    "    * покомпонентное среднее векторов слов, входящих в текст\n",
    "    * покомпонентный максимум векторов слов, входящих в текст\n",
    "* с использованием распределенных представлений текстов [doc embeddings]:\n",
    "    * doc2vec\n",
    "    * fastText\n",
    "    * снижение размерности в векторной модели, в т. ч. сингулярное разложение [singular value decomposition, SVD]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## (Напоминание) Вычисление расстояния / близости между документами \n",
    "\n",
    "Евклидово расстояние: $ dist( \\vec{d_i}, \\vec{d_j}) = \\sqrt { \\sum_{k} ( d_i^k - d_j^k)^2 }$\n",
    "\n",
    "Косинусная мера близости: $ sim( \\vec{d_i}, \\vec{d_j}) =  \\cos(\\theta )=  \\frac{ \\vec{d_i}\\cdot \\vec{d_j} }{\\| \\vec{d_i} \\|_{2}\\|\\vec{d_j} \\|_{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Метод ближайшего соседа  [Nearest neighbor classifier]\n",
    "\n",
    "Найдем $k$ ближайших соседей (самых близких документов) для документа $d$. Посмотрим на то, каким классам относятся документы: выберем модальный класс – будем считать его классом $d$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of bounds: 0 <= 0 <= 1, 0 <= 100 <= 1, 0 <= 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-51ad346dffd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwenty_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    302\u001b[0m                      row.step in (1, None))):\n\u001b[1;32m    303\u001b[0m                 \u001b[0;31m# col is int or slice with step 1, row is slice with step 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_submatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m# row is slice, col is sequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m_get_submatrix\u001b[0;34m(self, row_slice, col_slice)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mj0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mcheck_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mcheck_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mcheck_bounds\u001b[0;34m(i0, i1, num)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 raise IndexError(\n\u001b[1;32m    442\u001b[0m                       \u001b[0;34m\"index out of bounds: 0 <= %d <= %d, 0 <= %d <= %d,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m                       \" %d <= %d\" % (i0, num, i1, num, i0, i1))\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of bounds: 0 <= 0 <= 1, 0 <= 100 <= 1, 0 <= 100"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape\n",
    "X_train_counts[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier().fit(X_train_counts, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, \n",
    "                                 shuffle=True, random_state=42)\n",
    "X_test = count_vect.transform(twenty_test.data)\n",
    "print(X_test.shape)\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(predicted, twenty_test.target)\n",
    "micro_f1 = f1_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_p = precision_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_r = recall_score(predicted, twenty_test.target, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_p = precision_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_r = recall_score(predicted, twenty_test.target, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sns.heatmap(data=confusion_matrix(twenty_test.target, predicted), annot=True, fmt=\"d\", cbar=False, xticklabels=categories, yticklabels=categories)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "predicted = clf.predict(X_new_counts)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('{} => {}'.format(doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Метод наивного Байеса  [Multinomial naive Bayes classifier]\n",
    "\n",
    "Требуется оценить вероятность принадлежности документа $d \\in D$ классу $c \\in C$: $p(c|d)$. Каждый документ –  мешок слов, всего слов $|V|$.\n",
    "\t\n",
    "$p(c)$ – априорная вероятность класса $c$\n",
    "   \n",
    "$p(c|d)$ – апостериорная вероятность класса $c$\n",
    "\t\n",
    "\t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$ p(c|d) = \\frac{p(d|c)p(c)}{p(d)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Пусть документ $d$ описан признаками $f_1, \\dots, f_N$.\n",
    "\n",
    "$ c_{NB} = \\arg \\max _{c \\in C} p (c|d) = \\arg \\max_{c \\in C}  \\frac{p(d|c)p(c)}{p(d)} \\propto $\n",
    "\t\n",
    "$ \\propto \\arg \\max_{c \\in C} p(d|c)p(c)  = \\arg \\max_{c \\in C} p(f_1, f_2, \\dots, f_{N} | c)p(c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Предположение о независимости \n",
    "\n",
    "* Мешок слов: порядок слов не имеет значения\n",
    "* Условная независимость (наивное предположение): вероятности признаков $p(f_i|c_j)$ внутри класса $c_j$ независимы\n",
    "\n",
    "$p(f_1, f_2, \\dots, f_{N} | c) \\times  p(c) =   p(f_1|c) \\times p(f_2|c) \\times \\dots \\times p(f_{N}|c)  \\times p(c)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$C_{NB}=\\arg \\max_{c \\in C} p(c) \\times \\prod_{1 \\le i \\le N} p(f_i|c) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Допустим, что признаки $f_i$ – слова $w_i$, а $\\texttt{positions}$ – все позиции слов в документе.\n",
    "\n",
    "\n",
    "$C_{NB} = p(c) \\times \\prod_{i \\in \\texttt{positions}} p(w_i|c) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/bow.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Обучение наивного Байесовского классификатора\n",
    "\n",
    "#### ММП оценки вероятностей:\n",
    "\t\n",
    "$ \\widehat{p_(c_j)} = \\frac{| \\{d| d \\in c_j\\} |}{|D|} $\n",
    "\t\n",
    "$ \\widehat{p(w_i | c_j)} = \\frac{\\texttt{count}(w_i, c_j)}{\\sum_{w \\in V} \\texttt{count}(w, c_j)} $\n",
    "\t\n",
    "Создаем $|C|$ мегадокументов: каждый документ = все документы в одном классе, склеенные в один мегадокумент и вычисляем частоты $w$ в мегадокументах.\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Проблема нулевых вероятностей:  \n",
    "\n",
    "$\\texttt{count}(w_i, c_j)$ может быть равно нулю. \n",
    "\n",
    "Допустим, что каждое слово встречается как минимум $\\alpha$ раз в мешке слов.\n",
    "\t\n",
    "Преобразование Лапласа: $ \\frac{+\\alpha}{+\\alpha |V|}$\n",
    "\t\n",
    "$ \\widehat{p(w_i | c_j)} = \\frac{\\texttt{count}(w_i, c_j) + \\alpha}{(\\sum_{w \\in V} \\texttt{count}(w, c_j)) + \\alpha |V| } $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Пример. Тематическая классификация\n",
    "\t\n",
    "    \n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>документ</th>\n",
    "    <th>класс</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"4\">обучающее<br>множество</td>\n",
    "    <td>Chinese Beijing Chinese</td>\n",
    "    <td>c</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Chinese Chinese Shanghai</td>\n",
    "    <td>c</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Chinese Macao</td>\n",
    "    <td>c</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Tokyo Japan Chinese</td>\n",
    "    <td>j</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>тестовое<br>множество</td>\n",
    "    <td>Chinese Chinese Chinese Tokyo Japan</td>\n",
    "    <td>?</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "$p(c) =\\frac{3}{4}$,$p(j) = \\frac{1}{4}$\n",
    "\n",
    "$p(\\texttt{Chinese|c)}= (5+1)/(8+6)=6/14=3/7$  \n",
    "\n",
    "$p(\\texttt{Chinese|j)}= (1+1)/(3+6)=2/9$  \n",
    "\n",
    "$p(\\texttt{Tokyo|c)}= (0+1)/(8+6)=1/14$  \n",
    "\n",
    "$p(\\texttt{Tokyo|j)}= (1+1)/(3+6)=2/9$  \n",
    "\n",
    "$p(\\texttt{Japan|c)}= (0+1)/(8+6)=1/14$  \n",
    "\n",
    "$p(\\texttt{Japan|j)}= (1+1)/(3+6)=2/9$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$p(c|d_5) = 3/4 \\times (3/7)^3 \\times 1/14 \\times 1/14 \\approx 0.0003$\n",
    "\n",
    "$p(j|d_5) = 1/4 \\times (2/9)^3 \\times 2/9 \\times 2/9 \\approx 0.0001$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Мультиномиальный наивный Байсовский классификатор\n",
    "\n",
    "Слова в тексте распределены по мультиномиальному закону:\n",
    "\n",
    "$ p(d |c )={\\frac {(\\sum _{i}x_{i})!}{\\prod _{i}x_{i}!}}\\prod _{i}{p_{ki}}^{x_{i}} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_counts, twenty_train.target)\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(predicted, twenty_test.target)\n",
    "micro_f1 = f1_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_p = precision_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_r = recall_score(predicted, twenty_test.target, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_p = precision_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_r = recall_score(predicted, twenty_test.target, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(data=confusion_matrix(twenty_test.target, predicted), annot=True, fmt=\"d\", cbar=False, xticklabels=categories, yticklabels=categories)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "predicted = clf.predict(X_new_counts)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('{} => {}'.format(doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Логистическая регрессия (метод максимальной энтропии [MaxEnt])\n",
    "\n",
    "Требуется оценить вероятность принадлежности документа $d \\in D$ классу $c \\in C$: $p(c|d)$. Пусть заданы признаки  $f_i \\in F$ – множество признаков и  $w_i$ – их веса. \n",
    "\n",
    "Признаки могут зависеть от классов: $f_i(c,d)$  \n",
    "\n",
    "Линейная комбинация этих признаков: $\\sum_{i=1}^k w_i f_i(c,d)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Как связана $\\sum_{i=1}^k w_i f_i(c,x)$ и $p(c|d)$?\n",
    "\t\n",
    "$p(c|d) = \\frac{1}{Z} e^{\\sum_{i=1}^k w_i f_i(c,d)},$\n",
    "\t\n",
    "где $\\frac{1}{Z} = \\frac{1}{\\sum_{c' \\in C} e^{\\sum_{i=1}^k w_i f_i(c',d)} }.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$ \\widehat{c} = \\texttt{argmax}_{c \\in C} p (c|d) = \\texttt{argmax}_{c \\in C} \\frac{e^{\\sum_{i=1}^k w_i f_i(c,d)}}{\\sum_{c' \\in C} e^{\\sum_{i=1}^k w_i f_i(c',d)}}  \\propto  \\texttt{argmax}_{c \\in C} e^{\\sum_{i=1}^k w_i f_i(c,d)}   \\propto  \\texttt{argmax}_{c \\in C} \\sum_{i=1}^k w_i f_i(c,d).  $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Пример. Классификация по тональности на $C = <+,->$\n",
    "\t\n",
    "Используем индикаторные признаки\n",
    "\t\n",
    "\n",
    "*... there are virtually no surprises, and the writing is second-rate. So why did I enjoy it so much? For one thing, the cast is great ...*\n",
    "\t \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>признак</th>\n",
    "    <th>значение</th>\n",
    "    <th></th>\n",
    "    <th>вес</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$f_1$</td>\n",
    "    <td>1</td>\n",
    "    <td> \"great\" $\\in d$ и $c=+$</td>\n",
    "    <td rowspan=\"2\">1.9</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>0</td>\n",
    "    <td>иначе</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>$f_2$</td>\n",
    "    <td>1</td>\n",
    "    <td>\"second-rate\" $\\in d$ и $c=-$</td>\n",
    "    <td rowspan=\"2\">0.9</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>0</td>\n",
    "    <td>иначе</td>\n",
    "  </tr>\n",
    "\n",
    "   <tr>\n",
    "    <td>$f_3$</td>\n",
    "    <td>1</td>\n",
    "    <td>\"no\" $\\in d$ и $c=-$ </td>\n",
    "    <td rowspan=\"2\">0.7</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>0</td>\n",
    "    <td>иначе</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>$f_4$</td>\n",
    "    <td>1</td>\n",
    "    <td>\"enjoy\" $\\in d$ и $c=-$ </td>\n",
    "    <td rowspan=\"2\">-0.8</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>0</td>\n",
    "    <td>иначе</td>\n",
    "  </tr>\n",
    "\n",
    "   <tr>\n",
    "    <td>$f_4$</td>\n",
    "    <td>1</td>\n",
    "    <td>\"great\" $\\in d$ и $c=-$ </td>\n",
    "    <td rowspan=\"2\">-0.6</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>0</td>\n",
    "    <td>иначе</td>\n",
    "  </tr>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</table>\n",
    "\t\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "класс $+$:  $1.9 + 0 + 0 + 0 + 0 = 1.9$\n",
    "\t\n",
    "класс $-$: $0 + 0.9 + 0.7 - 0.8 - 0.6 =0.2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$p(+|d) = \\frac{e^{1.9}}{e^{1.9}+e^{0.2}}$\n",
    "\t\n",
    "$p(-|d) = \\frac{e^{0.2}}{e^{1.9}+e^{0.2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Поиск весов логистической регрессии\n",
    "\n",
    "Для каждой пары $(c,d)$: $ \\widehat{w} = \\texttt{argmax}_{w} \\log p(c|d) $\n",
    "\t\t\n",
    "Максимизация логарифмического правдоподобия: $L(w) =  \\sum_{j} \\log p(c_{j}|d) $\n",
    "\t\n",
    "При использовании индикаторных признаков, методы выпуклой оптимизации позволяют выбрать модель с максимальной энтропией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(X_train_counts, twenty_train.target)\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(predicted, twenty_test.target)\n",
    "micro_f1 = f1_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_p = precision_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_r = recall_score(predicted, twenty_test.target, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_p = precision_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_r = recall_score(predicted, twenty_test.target, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(data=confusion_matrix(twenty_test.target, predicted), annot=True, fmt=\"d\", cbar=False, xticklabels=categories, yticklabels=categories)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_new_counts)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('{} => {}'.format(doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Метод опорных векторов [Support vector machine, SVM]\n",
    "\n",
    "\n",
    "<img src=\"img/svm_1.png\" width=\"200\" align='right'>\n",
    "\n",
    "\n",
    "$a(x) = sign(<w,x>+b)$ – классификатор, задающий разделяющую гиперплоскость\n",
    "\n",
    "$ \\min_{x \\in X} |<w,x>+b| = 1$ – нормировка параметров\n",
    "\n",
    "Требуется построить разделяющую гиперплоскость шириной $ \\frac{2}{||w||}$ (т.е. $2 ~ \\times $ расстояние от разделяющей гиперплоскости до ближайшего объекта обучающего множества, иначе отступ).\n",
    "\n",
    "\n",
    "Оптимизационная задача (если выборка линейно разделима):\n",
    "\n",
    "$ \\frac{1}{2} ||w||^2 \\rightarrow \\min_{w,b} $\n",
    "\n",
    "$ y_i(<w_i, x_i> + b) \\geq 1 $\n",
    "\n",
    "\n",
    "\n",
    "Kernel trick: $k(x ,x')=\\langle  x ,x' \\rangle $.\n",
    "\n",
    "\n",
    "\n",
    "Конспекты Е. Соколова: https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/lecture-notes/lecture05-linclass.pdf\n",
    "\n",
    "Multi-class SVM: https://nlp.stanford.edu/IR-book/html/htmledition/multiclass-svms-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC().fit(X_train_counts, twenty_train.target)\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(predicted, twenty_test.target)\n",
    "micro_f1 = f1_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_p = precision_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_r = recall_score(predicted, twenty_test.target, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_p = precision_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_r = recall_score(predicted, twenty_test.target, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(data=confusion_matrix(twenty_test.target, predicted), annot=True, fmt=\"d\", cbar=False, xticklabels=categories, yticklabels=categories)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_new_counts)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('{} => {}'.format(doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Деревья решений \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/decision-tree.png\" width=\"300\" align='center'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier().fit(X_train_counts, twenty_train.target)\n",
    "predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(predicted, twenty_test.target)\n",
    "micro_f1 = f1_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_p = precision_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_r = recall_score(predicted, twenty_test.target, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_p = precision_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_r = recall_score(predicted, twenty_test.target, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(data=confusion_matrix(twenty_test.target, predicted), annot=True, fmt=\"d\", cbar=False, xticklabels=categories, yticklabels=categories)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Другие методы классификации\n",
    "\n",
    "**Линейные методы**: \n",
    "\n",
    "\n",
    "**Деревья решений**:\n",
    "\n",
    "* Градиентный бустинг [Xgboost]\n",
    "* Случайный лес [Random forest]\n",
    "\n",
    "\n",
    "\n",
    "**Ансамбли классификаторов**\n",
    "\n",
    "Общая идея: слова или $n$-грамы (термы) – это признаки, тексты – объекты, т.е. матрица терм-документ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Другие методы обучения\n",
    "\n",
    "**Active learning**\n",
    "\n",
    "**Semi supervised learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Кроссвалидация\n",
    "\n",
    "![title](img/cv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Отбор признаков\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Веса **:\n",
    "* $tf-idf$, $\\chi^2$ для взвешивания слов\n",
    "* меры ассоциации биграм для отбора биграм: $(P)PMI$, $t-score$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Уменьшение количества признаков **:\n",
    "* лемматизация\n",
    "* стемминг\n",
    "* удаление стоп-слов\n",
    "* пороги на частоту ($min\\_tf$)\n",
    "* пороги на документную частоту ($max\\_df$)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Признаки **:\n",
    "* $n$-грамы \n",
    "* символьные $n$-грамы  (подслова, subwords)\n",
    "* именованные сущности \n",
    "* термины\n",
    "* \"не\\_\" + слово \n",
    "* сохраним $N$ самых частых слов, остальные представим подсловами и символьные $n$-грамы\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Снижение размерности **:\n",
    "* скрытые темы в качестве признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Оптимизация гиперпараметров\n",
    "\n",
    "** Гиперпараметры **:\n",
    "* $n$ - длина $n$-грамы\n",
    "* пороги на частоту ($min\\_tf$)\n",
    "* пороги на документную частоту ($max\\_df$)\n",
    "* $\\alpha$ в преобразовании Лапласа \n",
    "* и др.\n",
    "\n",
    "\n",
    "![title](img/gs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Конвеер в sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range = (2,3))), \n",
    "                     ('tfidf', TfidfTransformer()), \n",
    "                     ('clf', MultinomialNB())])\n",
    "text_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "predicted = text_clf.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(predicted, twenty_test.target)\n",
    "micro_f1 = f1_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_p = precision_score(predicted, twenty_test.target, average = 'micro')\n",
    "micro_r = recall_score(predicted, twenty_test.target, average = 'micro')\n",
    "macro_f1 = f1_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_p = precision_score(predicted, twenty_test.target, average = 'macro')\n",
    "macro_r = recall_score(predicted, twenty_test.target, average = 'macro')\n",
    "print('acc={0:1.4f}'.format(acc))\n",
    "print('micro F1={0:1.4f}, micro P={1:1.4f}, micro R={2:1.4f}'.format(micro_f1, micro_p, micro_r))\n",
    "print('macro F1={0:1.4f}, macro P={1:1.4f}, macro R={2:1.4f}\\n'.format(macro_f1, macro_p, macro_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_new_counts)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('{} => {}'.format(doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Лабораторная работа\n",
    "\n",
    "Классификация новостных статей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Как на самом деле делается классификация по тональности \n",
    "\n",
    "* Классификация на уровне предложений: выражено ли в предложении отношение к чему-то?\n",
    "* Если да, то к чему – к каким аспектам?\n",
    "* Построение аггрегированной оценки\n",
    "\n",
    "![title](img/tonsum.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
